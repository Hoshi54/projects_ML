{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWTlbOLqZOBopsSIWuCzRw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hoshi54/projects_ML/blob/main/SHIFT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbEfzDE5aRS5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transform\n",
        "import torchvision\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "train_transform = transform.Compose(\n",
        "    [\n",
        "        transform.Resize((244,244)),\n",
        "        transform.RandomResizedCrop(244),\n",
        "        transform.RandomRotation(degrees = [10,15]),\n",
        "        transform.RandomHorizontalFlip(),\n",
        "        transform.ToTensor()\n",
        "    ]\n",
        ")\n",
        "\n",
        "test_transform = transform.Compose(\n",
        "    [\n",
        "        transform.Resize((244,244)),\n",
        "        transform.CenterCrop(244),\n",
        "        transform.ToTensor()\n",
        "    ]\n",
        ")\n",
        "\n",
        "df = pd.read_csv('/content/sign_mnist.csv')\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.3, stratify=df['label'], random_state=42)\n",
        "\n",
        "train_df.to_csv('train.csv', index=False)\n",
        "test_df.to_csv('test.csv', index=False)\n",
        "\n",
        "class SignDataset(Dataset):\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.data.iloc[idx, 1:].to_numpy().reshape(1, 28, 28)\n",
        "        label = self.data.iloc[idx]['label']\n",
        "        return torch.tensor(image).float(), torch.tensor(label)\n",
        "\n",
        "\n",
        "train_dataset = SignDataset('/content/train.csv',train_transform)\n",
        "test_dataset = SignDataset('/content/test.csv',test_transform)\n",
        "eval_dataset = SignDataset('/content/sign_mnist_test.csv')\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,shuffle = True,\n",
        "                                           batch_size = 32,num_workers = 2)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = train_dataset,shuffle = False,\n",
        "                                           batch_size = 32,num_workers = 2)\n",
        "\n",
        "eval_loader = torch.utils.data.DataLoader(dataset = eval_dataset,shuffle = False,\n",
        "                                      batch_size = 32,num_workers = 2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleNet,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels = 1,out_channels = 64,kernel_size = 5)\n",
        "    self.batch1 = nn.BatchNorm2d(64)\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size = 2,stride = 2)\n",
        "    self.conv2 = nn.Conv2d(in_channels = 64,out_channels = 128,kernel_size = 5)\n",
        "    self.batch2 = nn.BatchNorm2d(128)\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size = 2,stride = 2)\n",
        "    self.conv3 = nn.Conv2d(in_channels = 128,out_channels = 256,kernel_size = 5)\n",
        "    self.batch3 = nn.BatchNorm2d(256)\n",
        "    self.pool3 = nn.MaxPool2d(kernel_size = 2,stride = 2)\n",
        "    self.drop1 = nn.Dropout(0.25)\n",
        "    self.drop2 = nn.Dropout(0.5)\n",
        "    self.fc1 = nn.Linear(4 * 4 * 128,2000)\n",
        "    self.batch3 = nn.BatchNorm1d(2000)\n",
        "    self.fc2 = nn.Linear(2000,1000)\n",
        "    self.batch4 = nn.BatchNorm1d(1000)\n",
        "    self.fc3 = nn.Linear(1000,25)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.batch1(self.pool1(F.relu(self.conv1(x))))\n",
        "    x = self.batch2(self.pool2(F.relu(self.conv2(x))))\n",
        "    x = self.drop1(x)\n",
        "    x = x.view(-1,4 * 4 * 128)\n",
        "    x = self.batch3(F.relu(self.fc1(x)))\n",
        "    x = self.drop2(x)\n",
        "    x = self.batch4(F.relu(self.fc2(x)))\n",
        "    x = self.fc3(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "jZA0IMqUaS8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "id": "w5M1WwHIafKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "summary(SimpleNet(),(32,1,28,28))"
      ],
      "metadata": {
        "id": "b4v323f_aZpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from tqdm import tqdm_notebook\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#Зaморозка слоёв fc\n",
        "#fc = [model.fc1,model.fc2,model.fc3]\n",
        "#for fc in fc:\n",
        "#  for param in fc.parameters():\n",
        "#    param.requires_grad = False\n",
        "\n",
        "model = SimpleNet().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)\n",
        "\n",
        "lr_schedul = lr_scheduler.StepLR(optimizer,step_size = 1,gamma = 0.1)\n",
        "f1_train_l = []\n",
        "f1_test_l = []\n",
        "acc_train = []\n",
        "acc_test = []\n",
        "loss_train = []\n",
        "loss_te = []\n",
        "\n",
        "best_acc = 0\n",
        "best_model_wts = model.state_dict()\n",
        "for epoch in range(10):\n",
        "  train_acc = 0\n",
        "  total_train = 0\n",
        "  test_acc = 0\n",
        "  total_test = 0\n",
        "  for i,(images,labels) in enumerate(tqdm_notebook(train_loader)):\n",
        "    images,labels = images.to(device),labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(images)\n",
        "    loss = loss_fn(output,labels)\n",
        "    _,pred = torch.max(output,1)\n",
        "\n",
        "    f1_train = f1_score(labels.cpu(), pred.cpu(), average = 'weighted')\n",
        "\n",
        "    train_acc += (pred == labels).sum().item()\n",
        "    total_train += labels.size(0)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i,(images,labels) in enumerate(tqdm_notebook(test_loader)):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        output = model(images)\n",
        "        _,pred = torch.max(output,1)\n",
        "        test_acc += (pred == labels).sum().item()\n",
        "        total_test += labels.size(0)\n",
        "        loss_test = loss_fn(output,labels)\n",
        "        f1_test = f1_score(labels.cpu(), pred.cpu(), average='weighted')\n",
        "\n",
        "    if test_acc / total_test > best_acc:\n",
        "        best_acc = test_acc / total_test\n",
        "        best_model_wts = model.state_dict()\n",
        "\n",
        "  acc_train.append(train_acc / total_train)\n",
        "  acc_test.append(test_acc/total_test)\n",
        "  loss_train.append(float(loss))\n",
        "  loss_te.append(float(loss_test))\n",
        "  f1_train_l.append(f1_train)\n",
        "  f1_test_l.append(f1_test)\n",
        "  print('epoch {}/{} loss:{} accuracy_train:{} f1_train:{} | accuracy_test:{} f1_test:{}'.format(epoch + 1,10,loss,train_acc / total_train,f1_train,test_acc/total_test,f1_test))"
      ],
      "metadata": {
        "id": "0G5Fl4eLaiGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,(images,labels) in enumerate(tqdm_notebook(eval_loader)):\n",
        "   labels = labels.type(torch.LongTensor)\n",
        "   images = images.to(device)\n",
        "   labels = labels.to(device)\n",
        "\n",
        "   output = model(images)\n",
        "   _,pred = torch.max(output,1)\n",
        "   test_acc += (pred == labels).sum().item()\n",
        "   total_test += labels.size(0)\n",
        "   oss_test = loss_fn(output,labels)\n",
        "   f1_test = f1_score(labels.cpu(), pred.cpu(), average='weighted')\n",
        "\n",
        "print('accuracy_score:{},f1_test:{}'.format(test_acc / total_test,f1_test))"
      ],
      "metadata": {
        "id": "4GnPHYM1aor8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.title('Потери')\n",
        "plt.plot(loss_train,label = 'train loss')\n",
        "plt.plot(loss_te,label = 'test loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "268U1AaPaupw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Accuracy')\n",
        "plt.plot(acc_train,label = 'train acc')\n",
        "plt.plot(acc_test,label = 'test acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nXwzblrYaxW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('f1 score')\n",
        "plt.plot(f1_train_l,label = 'train f1')\n",
        "plt.plot(f1_test_l,label = 'test f1')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9w8dMr89a0a2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}